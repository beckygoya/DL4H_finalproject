# -*- coding: utf-8 -*-
"""DL4H_FinalProject_0425_combined.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VDzgmTQ0PnrgaIv30WeIszSw4tEprcHt
"""

import pandas as pd
import re
import numpy as np
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import f1_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn import preprocessing
import xgboost as xgb
from transformers import AutoTokenizer, AutoModel
import torch

from google.colab import drive
drive.mount('/content/drive')

# Load the annotated dataset
def load_annotation_data():
    annotation_path = "/content/drive/MyDrive/MIMIC-SBDH.csv"
    columns = ['row_id', 'sdoh_community_present', 'sdoh_community_absent',
               'sdoh_education', 'sdoh_economics', 'sdoh_environment',
               'behavior_alcohol', 'behavior_tobacco', 'behavior_drug']
    return pd.read_csv(annotation_path, usecols=columns)

# Load the original MIMIC-III discharge summaries
def load_mimic_data():
    mimic_path = "/content/drive/MyDrive/NOTEEVENTS.csv"
    mimic_data = pd.read_csv(
        mimic_path,
        usecols=['ROW_ID', 'TEXT', 'CATEGORY']
    )
    return mimic_data[mimic_data['CATEGORY'] == 'Discharge summary']

# Extract social history section from discharge summary
def extract_social_history(text):
    if pd.isna(text):
        return ""
    pattern = r"social history:\s*(.*?)(?=\n[a-z\s]+:|\Z)"
    match = re.search(pattern, text.lower(), re.DOTALL)
    return match.group(1).strip() if match else ""

# Merge and prepare the dataset
def prepare_dataset(annotated_data, mimic_data):
    annotated_data = annotated_data.rename(columns={'row_id':'ROW_ID'})
    merged = pd.merge(
        annotated_data,
        mimic_data[['ROW_ID', 'TEXT']],
        on='ROW_ID'
    )
    merged['social_history'] = merged['TEXT'].apply(extract_social_history)
    return merged[merged['social_history'] != ""]

# Enhanced feature extraction
def get_features(texts):
    return TfidfVectorizer(
        lowercase=True,
        stop_words='english',
        ngram_range=(1, 2),
        max_features=5000,
        token_pattern=r'[a-zA-Z]+'
    ).fit_transform(texts)

# Train Random Forest model that handles multiclass
def train_random_forest(X_train, y_train):
    return RandomForestClassifier(
        n_estimators=200,
        max_depth=None,
        min_samples_split=5,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    ).fit(X_train, y_train)

# Train XGBoost with proper multiclass handling
def train_xgboost(X_train, y_train):
    n_classes = len(np.unique(y_train))

    params = {
        'n_estimators': 200,
        'max_depth': 5,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'early_stopping_rounds': 10,
        'eval_metric': 'mlogloss' if n_classes > 2 else 'logloss'
    }

    if n_classes == 2:
        class_counts = np.bincount(y_train)
        params['scale_pos_weight'] = class_counts[0] / class_counts[1]
        params['objective'] = 'binary:logistic'
    else:
        params['objective'] = 'multi:softprob'
        params['num_class'] = n_classes

    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42
    )

    model = xgb.XGBClassifier(**params)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        verbose=False
    )
    return model

# Train logistic regression with proper multiclass handling
def train_logistic_reg(X_train, y_train):
    params = {
        'penalty': 'l2',
        'solver': 'lbfgs',
        'max_iter': 500,
        'class_weight': 'balanced',
        'random_state': 42,
    }

    model = LogisticRegression(**params)
    model.fit(X_train, y_train)
    return model

# Perform k-fold cross-validation that handles both binary and multiclass
def perform_cross_validation(texts, labels, model_type, n_splits=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    fold_results = []
    if model_type in ['lg','rf', 'xgb']:
      X = get_features(texts)
    elif model_type in ['bert-lg','bert-rf', 'bert-xgb']:
      X = texts
    classes = np.unique(labels)

    for train_idx, test_idx in kf.split(texts):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = labels.iloc[train_idx], labels.iloc[test_idx]

        if model_type in ['rf','bert-rf']:
            model = train_random_forest(X_train, y_train)
        elif model_type in ['xgb','bert-xgb']:
            model = train_xgboost(X_train, y_train)
        elif model_type in ['lg','bert-lg']:
            model = train_logistic_reg(X_train, y_train)

        y_pred = model.predict(X_test)

        f1_scores = f1_score(y_test, y_pred, average=None, labels=classes)
        fold_results.append({
            'macro_f1': f1_score(y_test, y_pred, average='macro'),
            'class_f1': {cls: score for cls, score in zip(classes, f1_scores)}
        })

    avg_class_f1 = {}
    std_class_f1 = {}
    for cls in classes:
        avg_class_f1[cls] = np.mean([r['class_f1'][cls] for r in fold_results])
        std_class_f1[cls] = np.std([r['class_f1'][cls] for r in fold_results])

    return {
        'avg_macro_f1': np.mean([r['macro_f1'] for r in fold_results]),
        'std_macro_f1': np.std([r['macro_f1'] for r in fold_results]),
        'avg_class_f1': avg_class_f1,
        'std_class_f1': std_class_f1
    }
# Main execution function
def main():
    data = prepare_dataset(load_annotation_data(), load_mimic_data())
    print(f"Number of samples: {len(data)}")

    sbdhs = ['sdoh_community_present', 'sdoh_community_absent',
             'sdoh_education', 'sdoh_economics', 'sdoh_environment',
             'behavior_alcohol', 'behavior_tobacco', 'behavior_drug']

    X = np.load('/content/drive/MyDrive/bert-embed.npy')
    scaler = preprocessing.StandardScaler().fit(X)
    X_normalized = scaler.transform(X)

    results = {}
    for sbdh in sbdhs:
        print(f"\n{'='*50}\nProcessing {sbdh}\n{'='*50}")
        print("Class distribution:")
        print(data[sbdh].value_counts())

        model_results = {}
        for model_type in ['rf','xgb', 'lg','bert-rf','bert-xgb', 'bert-lg']:
            print(f"\nEvaluating {model_type.upper()} model...")
            cv_results = perform_cross_validation(
                data['social_history'] if model_type in ['lg','rf', 'xgb'] else X_normalized,
                data[sbdh],
                model_type
            )

            print(f"Macro F1: {cv_results['avg_macro_f1']:.4f} ± {cv_results['std_macro_f1']:.4f}")
            for cls in sorted(cv_results['avg_class_f1'].keys()):
                print(f"Class {cls} F1: {cv_results['avg_class_f1'][cls]:.4f} ± {cv_results['std_class_f1'][cls]:.4f}")

            model_results[model_type] = cv_results

        results[sbdh] = model_results
    return results

if __name__ == "__main__":
    results = main()